{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(19)\n",
    "from model import encoderdecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--max_size'], dest='max_size', nargs=None, const=None, default=50, type=<type 'int'>, choices=None, help='max size of image pool, 0 means do not use image pool', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='')\n",
    "parser.add_argument('--dataset_dir', dest='dataset_dir', default='backpack', help='path of the dataset')\n",
    "parser.add_argument('--epoch', dest='epoch', type=int, default=200, help='# of epoch')\n",
    "parser.add_argument('--epoch_step', dest='epoch_step', type=int, default=100, help='# of epoch to decay lr')\n",
    "parser.add_argument('--batch_size', dest='batch_size', type=int, default=1, help='# images in batch')\n",
    "parser.add_argument('--train_size', dest='train_size', type=int, default=1e8, help='# images used to train')\n",
    "parser.add_argument('--load_size', dest='load_size', type=int, default=286, help='scale images to this size')\n",
    "parser.add_argument('--fine_size', dest='fine_size', type=int, default=256, help='then crop to this size')\n",
    "parser.add_argument('--ngf', dest='ngf', type=int, default=64, help='# of gen filters in first conv layer')\n",
    "parser.add_argument('--ndf', dest='ndf', type=int, default=64, help='# of discri filters in first conv layer')\n",
    "parser.add_argument('--input_nc', dest='input_nc', type=int, default=3, help='# of input image channels')\n",
    "parser.add_argument('--output_nc', dest='output_nc', type=int, default=1, help='# of output image channels')\n",
    "parser.add_argument('--lr', dest='lr', type=float, default=0.0002, help='initial learning rate for adam')\n",
    "# default beta1 (earlier 0.5)\n",
    "parser.add_argument('--beta1', dest='beta1', type=float, default=0.9, help='momentum term of adam')\n",
    "parser.add_argument('--which_direction', dest='which_direction', default='AtoB', help='AtoB or BtoA')\n",
    "parser.add_argument('--phase', dest='phase', default='train', help='train, test')\n",
    "parser.add_argument('--save_freq', dest='save_freq', type=int, default=1000, help='save a model every save_freq iterations')\n",
    "parser.add_argument('--print_freq', dest='print_freq', type=int, default=100, help='print the debug information every print_freq iterations')\n",
    "parser.add_argument('--continue_train', dest='continue_train', type=bool, default=False, help='if continue training, load the latest model: 1: true, 0: false')\n",
    "parser.add_argument('--checkpoint_dir', dest='checkpoint_dir', default='./checkpoint', help='models are saved here')\n",
    "parser.add_argument('--sample_dir', dest='sample_dir', default='./sample', help='sample are saved here')\n",
    "parser.add_argument('--test_dir', dest='test_dir', default='./test', help='test sample are saved here')\n",
    "#use Unet \n",
    "parser.add_argument('--use_resnet', dest='use_resnet', type=bool, default=False, help='generation network using reidule block')\n",
    "parser.add_argument('--use_lsgan', dest='use_lsgan', type=bool, default=True, help='gan loss defined in lsgan')\n",
    "parser.add_argument('--max_size', dest='max_size', type=int, default=50, help='max size of image pool, 0 means do not use image pool')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generatorA2B/g_e1_conv/Conv/weights:0\n",
      "generatorA2B/batch_norm/beta:0\n",
      "generatorA2B/batch_norm/gamma:0\n",
      "generatorA2B/g_e2_conv/Conv/weights:0\n",
      "generatorA2B/g_bn_e2/beta:0\n",
      "generatorA2B/g_bn_e2/gamma:0\n",
      "generatorA2B/g_d7/Conv2d_transpose/weights:0\n",
      "generatorA2B/g_bn_d7/beta:0\n",
      "generatorA2B/g_bn_d7/gamma:0\n",
      "generatorA2B/g_d8/Conv2d_transpose/weights:0\n",
      "Epoch: [ 0] [   0/ 481] time: 0.1130 loss: 0.3683\n",
      "Epoch: [ 0] [   1/ 481] time: 0.7772 loss: 0.3628\n",
      "Epoch: [ 0] [   2/ 481] time: 0.8632 loss: 0.3718\n",
      "Epoch: [ 0] [   3/ 481] time: 0.9648 loss: 0.3648\n",
      "Epoch: [ 0] [   4/ 481] time: 1.0653 loss: 0.3602\n",
      "Epoch: [ 0] [   5/ 481] time: 1.1621 loss: 0.4000\n",
      "Epoch: [ 0] [   6/ 481] time: 1.2508 loss: 0.3624\n",
      "Epoch: [ 0] [   7/ 481] time: 1.3330 loss: 0.4264\n",
      "Epoch: [ 0] [   8/ 481] time: 1.4330 loss: 0.3743\n",
      "Epoch: [ 0] [   9/ 481] time: 1.5309 loss: 0.3691\n",
      "Epoch: [ 0] [  10/ 481] time: 1.6260 loss: 0.3695\n",
      "Epoch: [ 0] [  11/ 481] time: 1.7229 loss: 0.3834\n",
      "Epoch: [ 0] [  12/ 481] time: 1.8004 loss: 0.3663\n",
      "Epoch: [ 0] [  13/ 481] time: 1.8978 loss: 0.3910\n",
      "Epoch: [ 0] [  14/ 481] time: 1.9847 loss: 0.6380\n",
      "Epoch: [ 0] [  15/ 481] time: 2.0790 loss: 0.3682\n",
      "Epoch: [ 0] [  16/ 481] time: 2.1673 loss: 0.4049\n",
      "Epoch: [ 0] [  17/ 481] time: 2.2601 loss: 0.3601\n",
      "Epoch: [ 0] [  18/ 481] time: 2.3486 loss: 0.3823\n",
      "Epoch: [ 0] [  19/ 481] time: 2.4464 loss: 0.4231\n",
      "Epoch: [ 0] [  20/ 481] time: 2.5352 loss: 0.3871\n",
      "Epoch: [ 0] [  21/ 481] time: 2.6284 loss: 0.3761\n",
      "Epoch: [ 0] [  22/ 481] time: 2.7254 loss: 0.3663\n",
      "Epoch: [ 0] [  23/ 481] time: 2.8130 loss: 0.3756\n",
      "Epoch: [ 0] [  24/ 481] time: 2.9034 loss: 0.3772\n",
      "Epoch: [ 0] [  25/ 481] time: 2.9970 loss: 0.3739\n",
      "Epoch: [ 0] [  26/ 481] time: 3.0853 loss: 0.3773\n",
      "Epoch: [ 0] [  27/ 481] time: 3.1712 loss: 0.3727\n",
      "Epoch: [ 0] [  28/ 481] time: 3.2655 loss: 0.5755\n",
      "Epoch: [ 0] [  29/ 481] time: 3.3572 loss: 0.3650\n",
      "Epoch: [ 0] [  30/ 481] time: 3.4592 loss: 0.3680\n",
      "Epoch: [ 0] [  31/ 481] time: 3.5520 loss: 0.4490\n",
      "Epoch: [ 0] [  32/ 481] time: 3.6466 loss: 0.3606\n",
      "Epoch: [ 0] [  33/ 481] time: 3.7381 loss: 0.3656\n",
      "Epoch: [ 0] [  34/ 481] time: 3.8251 loss: 0.3798\n",
      "Epoch: [ 0] [  35/ 481] time: 3.9009 loss: 0.4910\n",
      "Epoch: [ 0] [  36/ 481] time: 3.9904 loss: 0.3614\n",
      "Epoch: [ 0] [  37/ 481] time: 4.0889 loss: 0.3783\n",
      "Epoch: [ 0] [  38/ 481] time: 4.1748 loss: 0.3659\n",
      "Epoch: [ 0] [  39/ 481] time: 4.2650 loss: 0.4193\n",
      "Epoch: [ 0] [  40/ 481] time: 4.3710 loss: 0.4383\n",
      "Epoch: [ 0] [  41/ 481] time: 4.4514 loss: 0.3830\n",
      "Epoch: [ 0] [  42/ 481] time: 4.5485 loss: 0.3973\n",
      "Epoch: [ 0] [  43/ 481] time: 4.6446 loss: 0.4296\n",
      "Epoch: [ 0] [  44/ 481] time: 4.7350 loss: 0.3716\n",
      "Epoch: [ 0] [  45/ 481] time: 4.8285 loss: 0.3659\n",
      "Epoch: [ 0] [  46/ 481] time: 4.9204 loss: 0.3771\n",
      "Epoch: [ 0] [  47/ 481] time: 5.0121 loss: 0.3692\n",
      "Epoch: [ 0] [  48/ 481] time: 5.1004 loss: 0.3715\n",
      "Epoch: [ 0] [  49/ 481] time: 5.1858 loss: 0.4621\n",
      "Epoch: [ 0] [  50/ 481] time: 5.2803 loss: 0.3771\n",
      "Epoch: [ 0] [  51/ 481] time: 5.3631 loss: 0.4134\n",
      "Epoch: [ 0] [  52/ 481] time: 5.4545 loss: 0.3615\n",
      "Epoch: [ 0] [  53/ 481] time: 5.5387 loss: 0.3698\n",
      "Epoch: [ 0] [  54/ 481] time: 5.6283 loss: 0.3820\n",
      "Epoch: [ 0] [  55/ 481] time: 5.7275 loss: 0.3594\n",
      "Epoch: [ 0] [  56/ 481] time: 5.8239 loss: 0.3732\n",
      "Epoch: [ 0] [  57/ 481] time: 5.9150 loss: 0.3724\n",
      "Epoch: [ 0] [  58/ 481] time: 6.0083 loss: 0.3631\n",
      "Epoch: [ 0] [  59/ 481] time: 6.0918 loss: 0.3879\n",
      "Epoch: [ 0] [  60/ 481] time: 6.1810 loss: 0.3637\n",
      "Epoch: [ 0] [  61/ 481] time: 6.2876 loss: 0.7132\n",
      "Epoch: [ 0] [  62/ 481] time: 6.3684 loss: 0.4800\n",
      "Epoch: [ 0] [  63/ 481] time: 6.4700 loss: 0.3649\n",
      "Epoch: [ 0] [  64/ 481] time: 6.5701 loss: 0.3683\n",
      "Epoch: [ 0] [  65/ 481] time: 6.6664 loss: 0.3739\n",
      "Epoch: [ 0] [  66/ 481] time: 6.7675 loss: 0.3828\n",
      "Epoch: [ 0] [  67/ 481] time: 6.8643 loss: 0.3770\n",
      "Epoch: [ 0] [  68/ 481] time: 6.9518 loss: 0.3732\n",
      "Epoch: [ 0] [  69/ 481] time: 7.0302 loss: 0.4001\n",
      "Epoch: [ 0] [  70/ 481] time: 7.1294 loss: 0.3823\n",
      "Epoch: [ 0] [  71/ 481] time: 7.2009 loss: 0.5608\n",
      "Epoch: [ 0] [  72/ 481] time: 7.2961 loss: 0.3715\n",
      "Epoch: [ 0] [  73/ 481] time: 7.3864 loss: 0.3645\n",
      "Epoch: [ 0] [  74/ 481] time: 7.4743 loss: 0.3542\n",
      "Epoch: [ 0] [  75/ 481] time: 7.5643 loss: 0.3727\n",
      "Epoch: [ 0] [  76/ 481] time: 7.6525 loss: 0.3901\n",
      "Epoch: [ 0] [  77/ 481] time: 7.7424 loss: 0.3813\n",
      "Epoch: [ 0] [  78/ 481] time: 7.8271 loss: 0.3905\n",
      "Epoch: [ 0] [  79/ 481] time: 7.9160 loss: 0.3732\n",
      "Epoch: [ 0] [  80/ 481] time: 8.0001 loss: 0.3717\n",
      "Epoch: [ 0] [  81/ 481] time: 8.0799 loss: 0.3676\n",
      "Epoch: [ 0] [  82/ 481] time: 8.1762 loss: 0.3684\n",
      "Epoch: [ 0] [  83/ 481] time: 8.2614 loss: 0.3763\n",
      "Epoch: [ 0] [  84/ 481] time: 8.3531 loss: 0.3633\n",
      "Epoch: [ 0] [  85/ 481] time: 8.4398 loss: 0.3723\n",
      "Epoch: [ 0] [  86/ 481] time: 8.5327 loss: 0.3676\n",
      "Epoch: [ 0] [  87/ 481] time: 8.6209 loss: 0.3820\n",
      "Epoch: [ 0] [  88/ 481] time: 8.7071 loss: 0.3860\n",
      "Epoch: [ 0] [  89/ 481] time: 8.7965 loss: 0.4095\n",
      "Epoch: [ 0] [  90/ 481] time: 8.8858 loss: 0.4203\n",
      "Epoch: [ 0] [  91/ 481] time: 8.9688 loss: 0.3646\n",
      "Epoch: [ 0] [  92/ 481] time: 9.0585 loss: 0.3716\n",
      "Epoch: [ 0] [  93/ 481] time: 9.1445 loss: 0.3664\n",
      "Epoch: [ 0] [  94/ 481] time: 9.2240 loss: 0.3674\n",
      "Epoch: [ 0] [  95/ 481] time: 9.3130 loss: 0.3537\n",
      "Epoch: [ 0] [  96/ 481] time: 9.3957 loss: 0.6557\n",
      "Epoch: [ 0] [  97/ 481] time: 9.4805 loss: 0.3782\n",
      "Epoch: [ 0] [  98/ 481] time: 9.5647 loss: 0.3683\n",
      "Epoch: [ 0] [  99/ 481] time: 9.6462 loss: 0.3735\n",
      "Epoch: [ 0] [ 100/ 481] time: 9.8561 loss: 0.3869\n",
      "Epoch: [ 0] [ 101/ 481] time: 9.9378 loss: 0.3637\n",
      "Epoch: [ 0] [ 102/ 481] time: 10.0136 loss: 0.3759\n",
      "Epoch: [ 0] [ 103/ 481] time: 10.1026 loss: 0.3641\n",
      "Epoch: [ 0] [ 104/ 481] time: 10.1903 loss: 0.3710\n",
      "Epoch: [ 0] [ 105/ 481] time: 10.2745 loss: 0.3681\n",
      "Epoch: [ 0] [ 106/ 481] time: 10.3615 loss: 0.3700\n",
      "Epoch: [ 0] [ 107/ 481] time: 10.4451 loss: 0.3757\n",
      "Epoch: [ 0] [ 108/ 481] time: 10.5291 loss: 0.3665\n",
      "Epoch: [ 0] [ 109/ 481] time: 10.6102 loss: 0.3779\n",
      "Epoch: [ 0] [ 110/ 481] time: 10.6984 loss: 0.3703\n",
      "Epoch: [ 0] [ 111/ 481] time: 10.7778 loss: 0.3767\n",
      "Epoch: [ 0] [ 112/ 481] time: 10.8620 loss: 0.3642\n",
      "Epoch: [ 0] [ 113/ 481] time: 10.9485 loss: 0.3781\n",
      "Epoch: [ 0] [ 114/ 481] time: 11.0403 loss: 0.3789\n",
      "Epoch: [ 0] [ 115/ 481] time: 11.1417 loss: 0.4298\n",
      "Epoch: [ 0] [ 116/ 481] time: 11.2325 loss: 0.4103\n",
      "Epoch: [ 0] [ 117/ 481] time: 11.3206 loss: 0.4174\n",
      "Epoch: [ 0] [ 118/ 481] time: 11.4029 loss: 0.4375\n",
      "Epoch: [ 0] [ 119/ 481] time: 11.4908 loss: 0.3717\n",
      "Epoch: [ 0] [ 120/ 481] time: 11.5714 loss: 0.4976\n",
      "Epoch: [ 0] [ 121/ 481] time: 11.6524 loss: 0.3728\n",
      "Epoch: [ 0] [ 122/ 481] time: 11.7287 loss: 0.3878\n",
      "Epoch: [ 0] [ 123/ 481] time: 11.8186 loss: 0.4121\n",
      "Epoch: [ 0] [ 124/ 481] time: 11.9091 loss: 0.5673\n",
      "Epoch: [ 0] [ 125/ 481] time: 11.9981 loss: 0.3670\n",
      "Epoch: [ 0] [ 126/ 481] time: 12.0841 loss: 0.3728\n",
      "Epoch: [ 0] [ 127/ 481] time: 12.1782 loss: 0.3697\n",
      "Epoch: [ 0] [ 128/ 481] time: 12.2612 loss: 0.3669\n",
      "Epoch: [ 0] [ 129/ 481] time: 12.3495 loss: 0.3833\n",
      "Epoch: [ 0] [ 130/ 481] time: 12.4344 loss: 0.3801\n",
      "Epoch: [ 0] [ 131/ 481] time: 12.5213 loss: 0.3864\n",
      "Epoch: [ 0] [ 132/ 481] time: 12.6027 loss: 0.3607\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "losses = []\n",
    "#lrs = [0.0002, 0.002, 0.02, 0.00002]\n",
    "lrs = [0.05]\n",
    "for lr in lrs:\n",
    "    \n",
    "    args = parser.parse_args(['--dataset_dir=backpack', '--epoch=20', '--lr='+str(lr)])\n",
    "\n",
    "\n",
    "    if not os.path.exists(args.checkpoint_dir):\n",
    "        os.makedirs(args.checkpoint_dir)\n",
    "    if not os.path.exists(args.sample_dir):\n",
    "        os.makedirs(args.sample_dir)\n",
    "    if not os.path.exists(args.test_dir):\n",
    "        os.makedirs(args.test_dir)\n",
    "\n",
    "    tfconfig = tf.ConfigProto(allow_soft_placement=True)\n",
    "    tfconfig.gpu_options.allow_growth = True\n",
    "    \n",
    "    with tf.Session(config=tfconfig) as sess:\n",
    "        model = encoderdecoder(sess, args)\n",
    "        losses.append(model.train(args) if args.phase == 'train' \\\n",
    "            else model.test(args))\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "#     tf.app.run()\n",
    "\n",
    "for i in range(len(losses)):\n",
    "    print lrs[i], \" : \", losses[i][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(losses)):\n",
    "    print lrs[i], \" : \", sum(losses[i][-500:])*1.0/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
